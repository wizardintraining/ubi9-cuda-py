FROM quay.io/stewhite/ubi9-cuda-py:latest-devel as vllm-install

WORKDIR /opt/app-root/src

USER 1001

COPY --chown=1001:0 requirements-vllm-0.5.0.txt ./requirements.txt

RUN pip install --no-cache-dir -r requirements.txt && \
    rm -f requirements.txt && \
    # Install flash-attn from PyPI \
    pip install flash-attn~=2.5.9 --no-build-isolation && \
    # Correction for FIPS mode \
    sed -i s/md5/sha1/g /opt/app-root/lib64/python3.11/site-packages/triton/runtime/jit.py && \
    # Fix permissions to support pip in Openshift environments \
    chmod -R g+w /opt/app-root/lib/python3.11/site-packages && \
    fix-permissions /opt/app-root -P

##################
# vLLM container #
##################

FROM quay.io/stewhite/ubi9-cuda-py:latest as runtime-container

WORKDIR /opt/app-root/src

COPY --from=vllm-install --chown=1001:0 /opt/app-root/lib64/python3.11/site-packages /opt/app-root/lib64/python3.11/site-packages
COPY --from=vllm-install --chown=1001:0 /opt/app-root/src/.config/vllm/nccl/cu12/libnccl.so.2* /usr/local/lib/libnccl.so.2

# Fix VLLM_NCCL_SO_PATH
ENV VLLM_NCCL_SO_PATH=/usr/local/lib/libnccl.so.2

USER 1001

EXPOSE 8000

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]

